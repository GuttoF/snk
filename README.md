# Snake: AI üÜö A*

O jogo da cobrinha √© um cl√°ssico do nokia tijol√£o. Ele possui regras e objetivos simples, mas ainda sim √© bem dif√≠cil de zerar.

Ser√° que uma AI (rede neural) consegue zerar ele? E um algoritmo pathfinder (A*)? Qual dos dois se sairia melhor?

Nesse projeto vamos responder todas essas perguntas!

<p align="center">
  <img src="./Docs/01_dummy_classic.gif" width="500" style="border-radius: 10px; display: block; margin: auto auto" />
</p>

## 1 - Implementa√ß√£o do jogo

Acabei fazendo tudo em C#, por ser a linguagem que mais domino. Pra UI usei WPF, ent√£o infelizmente s√≥ vai rodar no Windows.

Tamb√©m implementei duas vers√µes do jogo:
- Uma mais simples, onde a cobra n√£o aumenta de tamanho ao pegar a comida.
- A vers√£o cl√°ssica, onde a cobra aumenta uma unidade a cada comida coletada.

Independente da vers√£o, √© preciso atingir uma pontua√ß√£o de 97 pontos para ganhar. Afinal, √© um tabuleiro 10x10 e a cobra inicia com tamanho 3.

Pensar em uma vers√£o mais simples do problema geralmente ajuda no entendimento e na solu√ß√£o do problema original.

<p align="center">
  <img src="./Docs/00_dummy_fixed_size.gif" width="500" style="border-radius: 10px;" />
  <img src="./Docs/01_dummy_classic.gif" width="500" style="border-radius: 10px;" />
</p>

Organizei o projeto em 3 partes:
- **Core**: aqui fica o estado do jogo, juntamente com suas regras
- **UI**: respons√°vel por mostrar na tela o estado atual do jogo
- **Players**: d√£o a dire√ß√£o pra cobra seguir, alterando o estado do jogo

No caso dos players, temos 4 op√ß√µes:
- **Human**: um humano pode jogar usando o teclado
- **Dummy**: um algoritmo simples (monte de if/else) que guia a cobra diretamente at√© a comida
- **Neural**: uma rede neural que recebe dados do estado do jogo e decide pra onde a cobra deve ir
- **Star**: um algoritmo A* modificado, que tamb√©m recebe o estado do jogo e define a pr√≥xima dire√ß√£o da cobra

Tamb√©m adicionei testes automatizados que validam tanto as regras do jogo (Core) quanto os algoritmos dos players.

A ideia de separar Core, UI e Players traz algumas vantagens:
- Consigo realizar testes unit√°rios em cada parte do sistema separadamente
- D√° pra avaliar o desempenho de cada player em milhares de jogos, apenas usando o Core (sem o custo de renderizar a UI)
- Pro caso do player Neural, √© poss√≠vel realizar o treinamento da rede apenas usando o Core (novamente, sem o custo de renderizar a UI)

<p align="center">
  <img src="./Docs/01_arch.gif" width="700" style="border-radius: 10px; display: block; margin: 0 auto" />
</p>

## 2 - Human

Esse player serviu apenas para que eu pudesse jogar durante a implementa√ß√£o.

At√© pensei em criar um modo onde √© poss√≠vel jogar contra os outros tipos de players:
- Um humano controlando uma cobra via teclado
- Um dos outros 3 algoritmos controlando outra cobra, dentro do mesmo ambiente
- Apenas uma comida aparece por vez, pra ver quem consegue chegar nela primeiro
- Colidir em si mesmo ou na outra cobra faz voc√™ perder o jogo

E mais interessante ainda seria um algoritmo contra o outro.

Mas isso tudo vai ficar pra uma v2 desse projeto...

## 3 - Dummy

Esse algoritmo √© o mais trivial poss√≠vel: um conjunto de if/else que direciona a cobrinha pra linha/coluna da comida.

Vou usar ele como base de compara√ß√£o pros outros dois algoritmos.

<p align="center">
  <img src="./Docs/algo_dummy.gif" width="700" style="border-radius: 10px; display: block; margin: 0 auto" />
</p>

## 4 - Neural

Rede neural √© uma t√©cnica de aprendizado de m√°quina inspirada no funcionamento do c√©rebro humano. Uma rede √© formada por neur√¥nios, organizados em camadas e conectados por meio de pesos ajust√°veis.

Podemos abstrair uma rede como sendo uma fun√ß√£o matem√°tica, que √© capaz de receber dados de entrada, precess√°-los e retornar uma sa√≠da.

No nosso caso, a rede vai pegar dados do estado atual do jogo, process√°-los internamente e no final retornar pra qual dire√ß√£o a cobra deve ir.

A rede neural desenvolvida neste projeto √© formada por:
- 4 neur√¥nios na camada de entrada
- 8 neur√¥nios na camada oculta
- 4 neur√¥nios na camada de sa√≠da

O treinamento dela foi feito utilizando um algortimo gen√©tico.

### 4.1 - Funcionamento

Durante o jogo, logo antes da cobra se movimentar, os dados do estado atual do jogo s√£o processados pela rede, que no final retorna para qual dire√ß√£o a cobra deve ir.

#### 4.1.1 Entrada

O diagrama a seguir mostra os dados de entrada da rede:
- **Œîx**: "dist√¢ncia" entre a cabe√ßa da cobra e comida na dire√ß√£o x.
  - Na pr√°tica, √© feita a subtra√ß√£o entre a coluna da comida e a da cobra:
    - Caso d√™ positivo, **Œîx=1**
    - Caso estejam na mesma coluna, **Œîx=0**
    - Caso d√™ negativo, **Œîx=-1**
- **Œîy**: "dist√¢ncia" entre a cabe√ßa da cobra e comida na dire√ß√£o y.
  - Na pr√°tica, √© feita a subtra√ß√£o entre a linha da comida e a da cobra:
    - Caso d√™ positivo, **Œîy=1**
    - Caso estejam na mesma linha, **Œîy=0**
    - Caso d√™ negativo, **Œîy=-1**
- **Vx**: velocidade da cobra no eixo x.
- **Vy**: velocidade da cobra no eixo y.

Perceba que as velocidades est√£o relacionadas, pois se a cobra est√° indo:
- Pra direita: **Vx=1** e **Vy=0**
- Pra baixo: **Vx=0** e **Vy=1**
- Pra esquerda: **Vx=-1** e **Vy=0**
- Pra cima: **Vx=0** e **Vy=-1**

<p align="center">
  <img src="./Docs/board_nn.gif" width="900" style="border-radius: 10px; display: block; margin: 0 auto" />
</p>

#### 4.1.2 Processamento

Cada linha tracejada ligando um neur√¥nio a outro possui um determinado peso. Esse peso √© um n√∫mero que pode variar entre -1000 e +1000. Quando uma rede √© criada, cada peso √© inicializado aleatoriamente (mas ainda dentro desses limites).

Cada neur√¥nio da camada oculta recebe os 4 valores de entrada (Œîx, Œîy, Vx e Vy), multiplica cada valor pelo seu respectivo peso e soma tudo no final.

Perceba que o valor dessa soma (S) √© no m√°ximo 3000, caso onde todos os pesos s√£o 1000, Œîx=Œîy=1, Vx=1 ou Vy=1.

Por fim, S √© dividido por 3000, para que a sa√≠da no neur√¥nio seja normalizada em um valor que fica sempre entre -1 e +1.

Esse processo se repete entre a camada oculta e a de sa√≠da, s√≥ que agora dividindo por 8000.

#### 4.1.3 Output

No final, o output de cada neur√¥nio de sa√≠da √© um num√©ro entre 0 e 1, pois pego apenas o valor absoluto do resultado da normaliza√ß√£o.

Assim, a cobra segue para a dire√ß√£o que retornou o maior valor absoluto de sa√≠da na rede.

### 4.2 - Treinamento (algoritmo gen√©tico)

O treinamento da rede serve para refinar o valor dos seus pesos.

Como foi dito antes, ao criar uma rede nova, todos os pesos s√£o inicializados aleatoriamente.

Como o conjunto dos pesos acaba por definir o comportamento da rede, precisamos de alguma forma ajustar cada valor para que a rede produza sa√≠das que levem a cobra a performar bem no jogo.

Existem v√°rias formas de fazer isso, mas aqui irei utilizar um algoritmo gen√©tico bem intuitivo:

‚ö†Ô∏è O processo a seguir ser√° repetido por 1000 gera√ß√µes ‚ö†Ô∏è

- 1Ô∏è‚É£ Vamos criar uma popula√ß√£o de 50.000 cobras, cada uma com seus pr√≥prios pesos aleat√≥rios
- 2Ô∏è‚É£ Cada cobra vai ser colocada pra jogar separadamente
- 3Ô∏è‚É£ Ao final de todos os jogos, vamos analisar o desempenho de cada cobra
- 4Ô∏è‚É£ Um hanking ser√° montado, ordenando as cobras com maior pontua√ß√£o e em seguida com o menor n√∫mero de movimentos realizados
- 5Ô∏è‚É£ As top 20% das cobras ser√£o selecionadas para jogarem na pr√≥xima gera√ß√£o
- 6Ô∏è‚É£ As pr√≥ximas 20% do hanking ser√£o cruzadas com as 20% anteriores, gerando novas cobras com relativo potencial no jogo
- 7Ô∏è‚É£ As demais ser√£o descartadas, ou melhor, substitu√≠das por novas cobras com pesos aleat√≥rios

Para evitar que uma cobra fique andando em c√≠rculos e o jogo nunca termine, defini um limite de passos que podem ser realizados antes do jogo acabar.

<p align="center">
  <img src="./Docs/nn_train.gif" width="900" style="display: block; margin: 0 auto" />
</p>

Ao final do treinamento, a melhor cobra (rede neural) ser√° selecionada para competir contra os demais players. Ela pode ser representada pelos pesos que ligam seus neur√¥nios e definem o comportamento da cobra no jogo.

Assim, todo treinamento √© feito com o objetivo de chegar em duas matrizes de pesos refinados, como as mostradas a seguir:

<p align="center">
  <img src="./Docs/nn_weights.png" width="400" style="display: block; margin: 0 auto" />
</p>

## 5 - Star

A parte mais dif√≠cil desse jogo √© quando a cobra ocupa mais da metade do tabuleiro. A partir da√≠ as chances de se prender no pr√≥prio corpo e perder o jogo s√≥ aumentam.

Para lidar com isso, o algoritmo a seguir se baseia em duas coisas:
- Limitar as dire√ß√µes de movimento da cobra em cada posi√ß√£o (seguindo um padr√£o bem definido)
- Buscar o menor caminho at√© a comida, respeitando o limite anterior (usando o algoritmo A*)

### 5.1 - Limitando os caminhos poss√≠veis

Para limitar as dire√ß√µes poss√≠veis de movimento da cobra em cada posi√ß√£o, repetimos o padr√£o a seguir por todo o tabuleiro.

Dessa forma, basta que a cobra respeite esses limites para que jamais fique sem sa√≠da e acabe perdendo o jogo.

<p align="center">
  <img src="./Docs/pattern_astar.gif" width="900" style="display: block; margin: 0 auto" />
</p>

### 5.2 - A* Pathfinder

Aqui utilizamos o algoritmo pathfinder A* para definir qual o menor caminho da cabe√ßa da cobra at√© a comida.

Caso n√£o seja poss√≠vel chegar at√© a comida, busca-se o menor caminho at√© a calda da cobra. Dessa forma, em algum momento a cobra vai chegar numa posi√ß√£o na qual √© poss√≠vel acessar a comida novamente.

A seguir podemos ver isso tudo funcionando:
- A cobra sempre se move respeitando as setas (limites de dire√ß√£o)
- Antes de cada movimento, ela calcula o menor caminho at√© a comida
- Os pontinhos amarelos no GIF representam o caminho calculado

<p align="center">
  <img src="./Docs/05_star_spoiler.gif" width="600" style="display: block; margin: 0 auto" />
</p>

## 6 - Vers√£o mais simples

Agora que j√° entendemos como o jogo e os algoritmos funcionam, vamos iniciar com a vers√£o mais simples do jogo, onde a cobra n√£o cresce ao pegar a comida.

√â esperado que todos os algoritmos se saiam bem nessa vers√£o, pois √© imposs√≠vel perder o jogo por colis√£o com o pr√≥prio corpo.

### 6.1 Dummy

Coloquei esse monte de if/else pra jogar 1000 partidas e ele ganhou (atingiu 97 pontos) em todas!

Veja que a quantidade de movimentos varia devido √† aleatoriedade do jogo, pois a comida pode aparecer em qualquer lugar vazio do tabuleiro.

A m√©dia de movimentos ficou em 678. A quantidade m√≠nima foi 581 e a m√°xima 812 movimentos.

<p align="center">
  <img src="./Docs/dummy_simple.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas completa:

<p align="center">
  <img src="./Docs/06_dummy_simple.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 6.2 Neural

O treinamento foi feito com 5000 cobras, jogando por 1000 gera√ß√µes, totalizando 5.000.000 de partidas.

As cobras rapidamente aprenderam a perseguir a comida, pois desde a primeira gera√ß√£o j√° surgiu pelo menos uma que ganhou o jogo.

A partir da√≠, as cobras que conseguiam zerar com o menor n√∫mero de movimentos foram sendo selecionadas e passadas para pr√≥xima gera√ß√£o.

<p align="center">
  <img src="./Docs/neural_simple_train.png" style="display: block; margin: 0 auto" />
</p>

No final foi obtida a cobra com o melhor desempenho, ou seja, que atinge a pontua√ß√£o m√°xima utilizando o menor n√∫mero de movimentos.

Coloquei ela pra jogar 1000 partidas e ela ganhou (atingiu 97 pontos) em todas!

A m√©dia de movimentos ficou em 958. A quantidade m√≠nima foi 817 e a m√°xima 1099 movimentos.

<p align="center">
  <img src="./Docs/neural_simple.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas completa:

<p align="center">
  <img src="./Docs/09_neural_simple.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 6.3 Star

Coloquei o Star pra jogar 1000 partidas e ele ganhou (atingiu 97 pontos) em todas!

A m√©dia de movimentos ficou em 765. A quantidade m√≠nima foi 631 e a m√°xima 901 movimentos.

<p align="center">
  <img src="./Docs/star_simple.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas completa:

<p align="center">
  <img src="./Docs/15_star_simple.gif" width="600" style="display: block; margin: 0 auto" />
</p>

## 7 - Vers√£o cl√°ssica

Finalmente vamos realizar a disputa na vers√£o cl√°ssica do jogo.

### 7.1 Dummy

Ela s√≥ conseguiu pegar em m√©dia 19 comidas, ou seja, s√≥ conseguiu ocupar 1/5 do tabuleiro.

<p align="center">
  <img src="./Docs/dummy_classic.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de duas partidas completas:

<p align="center">
  <img src="./Docs/19_dummy_classic.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 7.2 Neural

O treinamento foi feito com 10.000 cobras, jogando por 1000 gera√ß√µes, totalizando 10.000.000 de partidas.

Perceba que a cobra aprendeu a seguir um padr√£o de movimento circular, o que diminui as chances de colis√£o.

Durante o treinamento, algumas cobras conseguiram pontua√ß√µes muito altas (uma conseguiu at√© zerar), mas em m√©dia elas elas conseguem ocupar apenas metade do tabuleiro.

Esse comportamento de altas pontua√ß√µes apenas durante o treinamento se deve √† aleatoriedade do jogo: provavelmente as comidas foram aparecendo perto da cobra, evitando que ela colidisse consigo mesma.

<p align="center">
  <img src="./Docs/neural_classic.png" style="display: block; margin: 0 auto" />
</p>

Coloquei ela pra jogar 1000 partidas e ela n√£o conseguiu ganhar nenhuma.

A m√©dia de movimentos ficou em aaa. A quantidade m√≠nima foi aaa e a m√°xima aaa movimentos.

<p align="center">
  <img src="./Docs/neural_classic_game.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas completa:

<p align="center">
  <img src="./Docs/??" width="600" style="display: block; margin: 0 auto" />
</p>

### 7.3 Star

Coloquei o Star pra jogar 1000 partidas e ele ganhou (atingiu 97 pontos) em todas!

A m√©dia de movimentos ficou em xxx. A quantidade m√≠nima foi xxx e a m√°xima xxx movimentos.

Para ter mais confian√ßa que esse algoritmo sempre ganha, realizei mais 1.000.000 de jogos, e ele GANHOU TODOS.

<p align="center">
  <img src="./Docs/???" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas completa:

<p align="center">
  <img src="./Docs/???" width="600" style="display: block; margin: 0 auto" />
</p>

## 8 - Tabuleiros maiores

Coloquei o Star para jogar em tabuleiros maiores, para ver como se comporta quando o problema escala.

| Size    | Score | Steps | Time     |
|---------|-------|-------|----------|
| 10x10   |       |       | 60 s     |
| 20x20   |       |       |          |
| 50x50   |       |       |          |
| 100x100 |       |       |          |

GIF do 50x50:

## 9 - Veredito

Na vers√£o mais simples, o Dummy acabou tendo o melhor desempenho, seguido pelo Star e por fim o Neural.

J√° na vers√£o cl√°ssica, o Star foi perfeito, ganhando simplesmente todos os jogos que disputou. Dummy e Neural ficaram tecnicamente empatados.

## 10 - Refer√™ncias

### Victor Dias, do canal Universo Programado

Ele fez uma s√©rie com 3 v√≠deos no canal com diversos algoritmos e t√©cnicas para zerar o snake game.

No √∫ltimo v√≠deo ele apresenta essa sacada usada no player Star, onde basta limitar o padr√£o de movimento da cobra em cada posi√ß√£o para que ela nunca colida consigo mesma.

Segue o v√≠deo: https://youtu.be/Vii9XiQ8bec
