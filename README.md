# Snake: AI üÜö A*

[![Tests](https://github.com/ZaqueuCavalcante/snk/actions/workflows/tests.yml/badge.svg)](https://github.com/ZaqueuCavalcante/snk/actions/workflows/tests.yml)

O jogo da cobrinha √© um cl√°ssico do Nokia tijol√£o. Ele possui regras e objetivos simples, mas ainda sim √© bem dif√≠cil de zerar.

Ser√° que uma AI (rede neural) consegue zerar ele? E um algoritmo pathfinder (A*)? Qual dos dois se sairia melhor?

Nesse projeto vamos responder todas essas perguntas!

<p align="center">
  <img src="./Docs/00_star_classic_20x20.gif" width="500" style="border-radius: 10px; display: block; margin: auto auto" />
</p>

## 1 - Implementa√ß√£o do jogo

Acabei fazendo tudo em C#, por ser a linguagem que mais domino. Pra UI usei WPF, ent√£o infelizmente s√≥ vai rodar no Windows.

Tamb√©m implementei duas vers√µes do jogo:
- Uma mais simples, onde a cobra n√£o aumenta de tamanho ao pegar a comida.
- A cl√°ssica, onde a cobra aumenta uma unidade a cada comida coletada.

Pensar em uma vers√£o mais simples do problema geralmente ajuda no entendimento e na resolu√ß√£o do problema original.

<p align="center">
  <img src="./Docs/01_dummy_fixed_size_10x10.gif" width="500" style="border-radius: 10px;" />
  <img src="./Docs/02_dummy_classic_10x10.gif" width="500" style="border-radius: 10px;" />
</p>

Organizei o projeto em 3 partes:
- **Core**: aqui fica o estado do jogo, juntamente com suas regras
- **UI**: respons√°vel por mostrar na tela o estado atual do jogo
- **Players**: d√£o a dire√ß√£o pra cobra seguir, alterando o estado do jogo

No caso dos players, temos 4 op√ß√µes:
- **Human**: um humano pode jogar usando o teclado
- **Dummy**: um algoritmo simples (monte de if/else) que guia a cobra diretamente at√© a comida
- **Neural**: uma rede neural que recebe dados do estado do jogo e decide pra onde a cobra deve ir
- **Star**: um algoritmo A* modificado, que tamb√©m recebe o estado do jogo e define a pr√≥xima dire√ß√£o da cobra

Tamb√©m adicionei **testes automatizados** que validam tanto as regras do jogo (Core) quanto os algoritmos dos players.

A ideia de separar Core, UI e Players traz algumas vantagens:
- Consigo realizar testes unit√°rios em cada parte do sistema separadamente
- D√° pra avaliar o desempenho de cada player em milhares de jogos, apenas usando o Core (sem o custo de renderizar a UI)
- Pro caso do player Neural, √© poss√≠vel realizar o treinamento da rede apenas usando o Core (novamente, sem o custo de renderizar a UI)

<p align="center">
  <img src="./Docs/03_project_arch.gif" width="700" style="border-radius: 10px; display: block; margin: 0 auto" />
</p>

## 2 - Human

Esse player serviu apenas para que eu pudesse jogar durante a implementa√ß√£o.

At√© pensei em criar um modo onde √© poss√≠vel jogar contra os outros players:
- Um humano controlando uma cobra via teclado
- Um dos outros 3 algoritmos controlando outra cobra, dentro do mesmo ambiente
- Apenas uma comida aparece por vez, pra ver quem consegue chegar nela primeiro
- Colidir em si mesmo ou na outra cobra faz voc√™ perder o jogo

E mais interessante ainda seria um algoritmo contra o outro.

Mas isso tudo vai ficar pra uma v2 desse projeto...

## 3 - Dummy

Esse algoritmo √© o mais trivial poss√≠vel: um conjunto de if/else que direciona a cobrinha pra linha/coluna da comida.

Vou usar ele como base de compara√ß√£o pros outros dois algoritmos (Neural e Star).

<p align="center">
  <img src="./Docs/04_dummy_code.gif" width="700" style="border-radius: 10px; display: block; margin: 0 auto" />
</p>

## 4 - Neural

Rede neural √© uma t√©cnica de aprendizado de m√°quina inspirada no funcionamento do c√©rebro humano. Uma rede √© formada por **neur√¥nios**, que s√£o organizados em **camadas** e conectados por meio de **pesos ajust√°veis**.

Podemos abstrair uma rede como sendo uma **fun√ß√£o**, que √© capaz de receber dados de entrada, precess√°-los e retornar uma sa√≠da.

No nosso caso, a rede vai pegar dados do estado atual do jogo, process√°-los internamente e no final retornar pra qual dire√ß√£o a cobra deve ir.

A rede neural desenvolvida neste projeto √© formada por:
- 4 neur√¥nios na camada de entrada
- 8 neur√¥nios na camada oculta
- 4 neur√¥nios na camada de sa√≠da

O treinamento dela foi feito utilizando um **algortimo gen√©tico**.

### 4.1 - Funcionamento

Durante o jogo, logo antes da cobra se movimentar, os dados do estado atual do jogo s√£o processados pela rede, que no final retorna para qual dire√ß√£o a cobra deve ir.

#### 4.1.1 Entrada

O diagrama a seguir mostra os dados de entrada da rede:
- **Œîx**: "dist√¢ncia" entre a cabe√ßa da cobra e comida na dire√ß√£o x.
  - Na pr√°tica, √© feita a subtra√ß√£o entre a **coluna** da comida e a da cobra:
    - Caso d√™ positivo, **Œîx=1**
    - Caso estejam na mesma coluna, **Œîx=0**
    - Caso d√™ negativo, **Œîx=-1**
- **Œîy**: "dist√¢ncia" entre a cabe√ßa da cobra e comida na dire√ß√£o y.
  - Na pr√°tica, √© feita a subtra√ß√£o entre a **linha** da comida e a da cobra:
    - Caso d√™ positivo, **Œîy=1**
    - Caso estejam na mesma linha, **Œîy=0**
    - Caso d√™ negativo, **Œîy=-1**
- **Vx**: velocidade da cobra no eixo x.
- **Vy**: velocidade da cobra no eixo y.

Perceba que as velocidades est√£o relacionadas, pois se a cobra est√° indo:
- Pra direita: **Vx=1** e **Vy=0**
- Pra esquerda: **Vx=-1** e **Vy=0**
- Pra baixo: **Vx=0** e **Vy=1**
- Pra cima: **Vx=0** e **Vy=-1**

<p align="center">
  <img src="./Docs/05_grid_neural_network.gif" width="900" style="border-radius: 10px; display: block; margin: 0 auto" />
</p>

#### 4.1.2 Processamento

Cada **linha tracejada** ligando um neur√¥nio a outro possui um determinado **peso**. Esse peso √© um n√∫mero que pode variar entre -1000 e +1000. Quando uma rede √© criada, cada peso √© inicializado **aleatoriamente** (mas ainda dentro desses limites).

Cada neur√¥nio da camada oculta recebe os 4 valores de entrada (Œîx, Œîy, Vx e Vy) e os processa, utilizando os respectivos pesos que interligam os neur√¥nios.

A sa√≠da da camada oculta serve de entrada para a √∫ltima camada da rede, que vai processar os dados e no final dizer pra qual dire√ß√£o a cobra deve seguir.

#### 4.1.3 Output

No final, o output de cada neur√¥nio de sa√≠da √© um num√©ro entre 0 e 1. Dessa forma, a cobra acaba seguindo para a dire√ß√£o que retornou o maior valor entre a 4 sa√≠das.

### 4.2 - Treinamento (algoritmo gen√©tico)

O treinamento da rede serve para refinar o valor dos seus pesos.

Como foi dito antes, ao criar uma rede nova, todos os pesos s√£o inicializados aleatoriamente.

Como o conjunto dos pesos acaba por definir o comportamento da rede, precisamos de alguma forma ajustar cada valor para que a rede produza sa√≠das que levem a cobra a performar bem no jogo.

Existem v√°rias formas de fazer isso, mas aqui irei utilizar um algoritmo gen√©tico bem intuitivo:

‚ö†Ô∏è O processo a seguir ser√° repetido por 1000 gera√ß√µes ‚ö†Ô∏è

- 1Ô∏è‚É£ Vamos criar uma popula√ß√£o de 5000 cobras, cada uma com seus pr√≥prios pesos aleat√≥rios
- 2Ô∏è‚É£ Cada cobra vai ser colocada pra jogar separadamente
- 3Ô∏è‚É£ Ao final de todos os jogos, vamos analisar o desempenho de cada cobra
- 4Ô∏è‚É£ Um hanking ser√° montado, ordenando as cobras com maior pontua√ß√£o e com o menor n√∫mero de movimentos realizados
- 5Ô∏è‚É£ As top 20% das cobras ser√£o selecionadas para jogarem na pr√≥xima gera√ß√£o
- 6Ô∏è‚É£ As pr√≥ximas 20% do hanking ser√£o cruzadas com as 20% anteriores, gerando novas cobras com relativo desempenho no jogo
- 7Ô∏è‚É£ As demais ser√£o descartadas, ou melhor, substitu√≠das por novas cobras com pesos aleat√≥rios

Para evitar que uma cobra fique andando em c√≠rculos e o jogo nunca termine, defini um limite de passos que podem ser realizados antes do jogo acabar.

<p align="center">
  <img src="./Docs/06_neural_network_train.gif" style="display: block; margin: 0 auto" />
</p>

Ao final do treinamento, a melhor cobra (rede neural) ser√° selecionada para competir contra os demais players. Ela pode ser representada pelos pesos que ligam seus neur√¥nios e definem o comportamento da cobra no jogo.

Assim, todo treinamento √© feito com o objetivo de chegar em duas matrizes de pesos refinados, como as mostradas a seguir:

<p align="center">
  <img src="./Docs/07_neural_network_weights.png" width="400" style="display: block; margin: 0 auto" />
</p>

## 5 - Star

A parte mais dif√≠cil desse jogo come√ßa quando a cobra ocupa cerca de metade do tabuleiro. A partir da√≠ as chances de se prender no pr√≥prio corpo e perder o jogo s√≥ aumentam.

Para lidar com isso, o algoritmo a seguir se baseia em 3 coisas:
- **Limitar as dire√ß√µes** de movimento da cobra em cada posi√ß√£o (seguindo um padr√£o bem definido)
- Buscar o **menor caminho at√© a comida**, respeitando o limite anterior (usando o algoritmo A*)
- Evitar ao m√°ximo que a cobra crie **regi√µes vazias fechadas** no tabuleiro, para que a comida surja em locais mais acess√≠veis

### 5.1 - Limitando as dire√ß√µes

Para limitar as dire√ß√µes poss√≠veis de movimento da cobra em cada posi√ß√£o, repetimos o padr√£o a seguir por todo o tabuleiro.

Dessa forma, basta que a cobra respeite esses limites para que jamais fique sem sa√≠da e acabe perdendo o jogo.

<p align="center">
  <img src="./Docs/08_star_pattern.gif" width="900" style="display: block; margin: 0 auto" />
</p>

### 5.2 - Buscando o menor caminho

Aqui utilizamos o algoritmo pathfinder A* para definir qual o menor caminho da cabe√ßa da cobra at√© a comida.

Caso n√£o seja poss√≠vel chegar at√© a comida, busca-se o menor caminho at√© a calda da cobra. Dessa forma, em algum momento a cobra vai chegar numa posi√ß√£o em que √© poss√≠vel acessar a comida novamente.

A seguir podemos ver isso tudo funcionando:
- A cobra sempre se move respeitando as setas (limites de dire√ß√£o)
- Antes de cada movimento, ela calcula o menor caminho at√© a comida
- Os pontinhos amarelos no GIF representam o caminho calculado

<p align="center">
  <img src="./Docs/09_star_classic_10x10_spoiler.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 5.3 Evitando regi√µes vazias fechadas

Ao se mover sempre buscando o menor caminho, a cobra acaba criando regi√µes vazias fechadas no tabuleiro.

Quando uma comida aparece nesses locais, √© preciso seguir a calda at√© que a cobra possa acessar a regi√£o da comida novamente.

Isso geralmente custa muitos movimentos, o que impacta significativamente no desempenho final da cobra.

Para lidar com esse problema, imagine que a cobra possui duas dire√ß√µes pra seguir (D1 e D2):
- Se ir na dire√ß√£o D1 produz uma regi√£o fechada, mas ir na dire√ß√£o D2 n√£o, ent√£o a cobra acaba indo pra D2
- A mesma l√≥gica se aplica pro caso de D2 gerar regi√£o fechada e D1 n√£o
- Caso as duas produzam ou nenhuma das duas produza, a cobra vai pelo menor caminho, como definido no passo anterior

Veja a seguir um exemplo de gera√ß√£o de regi√µes vazias e de como elas reduzem a efici√™ncia da cobra:

<p align="center">
  <img src="./Docs/10_star_classic_10x10_empty_regions.gif" width="600" style="display: block; margin: 0 auto" />
</p>

## 6 - Vers√£o mais simples

Agora que j√° entendemos como o jogo e os algoritmos funcionam, vamos iniciar com a vers√£o mais simples, onde a cobra n√£o cresce ao pegar a comida.

√â esperado que todos os algoritmos se saiam bem nessa vers√£o, pois √© imposs√≠vel perder o jogo por colis√£o com o pr√≥prio corpo.

### 6.1 Dummy

O player Dummy jogou 1000 partidas e ganhou (atingiu 97 pontos) todas!

Veja que a quantidade de movimentos total varia devido √† aleatoriedade do jogo, pois a comida pode aparecer em qualquer lugar vazio do tabuleiro.

A m√©dia de movimentos at√© zerar ficou em 678. A quantidade m√≠nima foi 581 e a m√°xima 812 movimentos.

<p align="center">
  <img src="./Docs/11_dummy_fixed_size_10x10_1000_games_steps.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas:

<p align="center">
  <img src="./Docs/12_dummy_fixed_size_10x10_complete.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 6.2 Neural

O treinamento foi feito com 5000 cobras, jogando por 1000 gera√ß√µes, totalizando 5.000.000 de partidas.

As cobras rapidamente aprenderam a perseguir a comida, pois desde a primeira gera√ß√£o j√° surgiu pelo menos uma que ganhou o jogo (atingiu 97 pontos).

A partir da√≠, as cobras que conseguiam zerar com o menor n√∫mero de movimentos foram sendo selecionadas e passadas para pr√≥xima gera√ß√£o.

Podemos verificar a seguir a queda na m√©dia de movimentos com o passar das gera√ß√µes:

<p align="center">
  <img src="./Docs/13_neural_fixed_size_10x10_train.png" style="display: block; margin: 0 auto" />
</p>

No final foi obtida a cobra com o melhor desempenho, ou seja, que atinge a pontua√ß√£o m√°xima utilizando o menor n√∫mero de movimentos.

O player Neural tamb√©m jogou 1000 partidas e ganhou (atingiu 97 pontos) todas!

A m√©dia de movimentos ficou em 958. A quantidade m√≠nima foi 817 e a m√°xima 1099 movimentos.

<p align="center">
  <img src="./Docs/14_neural_simple.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas:

<p align="center">
  <img src="./Docs/15_neural_simple.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 6.3 Star

O player Star tamb√©m jogou 1000 partidas e ganhou (atingiu 97 pontos) todas!

A m√©dia de movimentos ficou em 765. A quantidade m√≠nima foi 631 e a m√°xima 901 movimentos.

<p align="center">
  <img src="./Docs/16_star_simple.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas:

<p align="center">
  <img src="./Docs/17_star_simple.gif" width="600" style="display: block; margin: 0 auto" />
</p>

## 7 - Vers√£o cl√°ssica

Finalmente vamos realizar a disputa na vers√£o cl√°ssica do jogo.

### 7.1 Dummy

Ela s√≥ conseguiu pegar em m√©dia 19 comidas, ou seja, s√≥ conseguiu ocupar 1/5 do tabuleiro antes de morrer.

O valor m√°ximo de 43 pontos se deve ao fato que a comida aparece em locais aleat√≥rios, de forma que a cobra teve sorte da comida nascer em locais favor√°reis.

Como o algoritmo n√£o usa nenhuma estrat√©gia para evitar que a cobra fique sem sa√≠da, seu desempenho geral acaba sendo extremamente baixo.

<p align="center">
  <img src="./Docs/18_dummy_classic.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de duas partidas completas (com desempenhos de 20 e 31 pontos):

<p align="center">
  <img src="./Docs/19_dummy_classic.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 7.2 Neural

O treinamento foi feito com 10.000 cobras, jogando por 1000 gera√ß√µes, totalizando 10.000.000 de partidas.

Durante o treinamento, algumas cobras conseguiram pontua√ß√µes muito altas (uma conseguiu at√© zerar), mas em m√©dia elas conseguem ocupar apenas metade do tabuleiro.

Esse comportamento de altas pontua√ß√µes apenas durante o treinamento se deve √† aleatoriedade do jogo: provavelmente as comidas foram aparecendo perto da cobra, evitando que ela colidisse consigo mesma.

<p align="center">
  <img src="./Docs/20_neural_classic.png" style="display: block; margin: 0 auto" />
</p>

Nessa vers√£o o player Neural jogou as 1000 partidas, mas n√£o conseguiu ganhar nenhuma.

A pontua√ß√£o m√©dia foi de 34 pontos, com m√≠nima de 17 e m√°xima de 74.

A m√©dia de movimentos ficou em 874, com m√≠nima de 355 e m√°xima de 2500.

<p align="center">
  <img src="./Docs/21_neural_classic_game.png" style="display: block; margin: 0 auto" />
</p>

Perceba que a cobra aprendeu a seguir um padr√£o de movimento circular anti-hor√°rio, o que diminui as chances de colis√£o, mas ainda √© ineficiente em rela√ß√£o √† quantidade de movimentos.

Segue o GIF de uma das partidas:

<p align="center">
  <img src="./Docs/22_neural_best_classic.gif" width="600" style="display: block; margin: 0 auto" />
</p>

### 7.3 Star

O player Star jogou 1000 partidas e ganhou (atingiu 97 pontos) todas!

A m√©dia de movimentos ficou em 1332, com m√≠nima de 899 e m√°xima 1744.

Para ter mais confian√ßa que esse algoritmo sempre ganha, realizei mais 100.000 jogos e ele GANHOU TODOS.

<p align="center">
  <img src="./Docs/23_star_classic.png" style="display: block; margin: 0 auto" />
</p>

Segue o GIF de uma das partidas:

<p align="center">
  <img src="./Docs/24_star_best_classic.gif" width="600" style="display: block; margin: 0 auto" />
</p>

## 8 - Tabuleiros maiores

Coloquei o Star para jogar em tabuleiros maiores, para ver como se comporta quando o problema escala.

| Size    | Score  | Steps     | Time   |
|---------|--------|-----------|--------|
| 10x10   | 97     | 1.140     | 0.2 s  |
| 20x20   | 397    | 13.623    | 2 s    |
| 30x30   | 897    | 69.296    | 25 s   |
| 40x40   | 1.597  | 226.289   | 3 min  |
| 50x50   | 2.497  | 616.980   | 18 min |

Veja o GIF do 20x20 (cortei algumas partes do meio):

<p align="center">
  <img src="./Docs/25_star_20_20.gif" width="600" style="display: block; margin: 0 auto" />
</p>

## 9 - Veredito

Na vers√£o mais simples, o Dummy acabou tendo o melhor desempenho, seguido pelo Star e por fim o Neural.

J√° na vers√£o cl√°ssica, o Star foi o melhor, ganhando todos os jogos que disputou. O Neural ficou em segundo lugar e o Dummy em √∫ltimo.

## 10 - Refer√™ncias

### Victor Dias, do canal Universo Programado

Ele fez uma s√©rie com 3 v√≠deos no canal com diversos algoritmos e t√©cnicas para zerar o snake game.

No √∫ltimo v√≠deo ele apresenta essa sacada usada no player Star, onde basta limitar o padr√£o de movimento da cobra em cada posi√ß√£o para que ela nunca colida consigo mesma.

Segue o v√≠deo: https://youtu.be/Vii9XiQ8bec

### Gr√°ficos e estat√≠sticas

- Utilizei o Briefer pra gerar os gr√°ficos, √© muito simples de usar e de baixar as imagens.
